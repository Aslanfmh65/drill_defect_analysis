{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import helper_function\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from keras.utils import np_utils\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code if you need to clean and augment the data\n",
    "data_processor = helper_function.data_processing()\n",
    "dataset = data_processor.load_data() \n",
    "cleaned_dataset = data_processor.preprocessing(dataset)\n",
    "augmented_dataset = data_processor.augment_save(cleaned_dataset) \n",
    "# export_csv = augmented_dataset.to_csv (\"cleaned_augmented_data.csv\", index = True, header=True)\n",
    "\n",
    "\n",
    "# ## Run this code if you need to save the cleaned and original data\n",
    "# states = ['fw_clean.csv', 'cw_clean.csv', 'oc_clean.csv', 'pe_clean.csv']\n",
    "# for i in range(len(cleaned_dataset)):\n",
    "#     clean_data = cleaned_dataset[i]\n",
    "#     # Save the cleaned data\n",
    "#     export_csv = clean_data.to_csv (states[i], index = True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.039326</td>\n",
       "      <td>0.394546</td>\n",
       "      <td>0.409402</td>\n",
       "      <td>0.351845</td>\n",
       "      <td>0.420885</td>\n",
       "      <td>0.563941</td>\n",
       "      <td>0.614782</td>\n",
       "      <td>0.535529</td>\n",
       "      <td>0.488066</td>\n",
       "      <td>0.488956</td>\n",
       "      <td>0.622206</td>\n",
       "      <td>0.564322</td>\n",
       "      <td>0.558791</td>\n",
       "      <td>0.486849</td>\n",
       "      <td>0.634305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.036779</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.418747</td>\n",
       "      <td>0.363013</td>\n",
       "      <td>0.415712</td>\n",
       "      <td>0.566265</td>\n",
       "      <td>0.611670</td>\n",
       "      <td>0.521770</td>\n",
       "      <td>0.484384</td>\n",
       "      <td>0.507496</td>\n",
       "      <td>0.639967</td>\n",
       "      <td>0.562287</td>\n",
       "      <td>0.561557</td>\n",
       "      <td>0.508049</td>\n",
       "      <td>0.631369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.040571</td>\n",
       "      <td>0.479242</td>\n",
       "      <td>0.422629</td>\n",
       "      <td>0.373950</td>\n",
       "      <td>0.435482</td>\n",
       "      <td>0.561222</td>\n",
       "      <td>0.608771</td>\n",
       "      <td>0.512395</td>\n",
       "      <td>0.484983</td>\n",
       "      <td>0.524696</td>\n",
       "      <td>0.650727</td>\n",
       "      <td>0.569639</td>\n",
       "      <td>0.563530</td>\n",
       "      <td>0.527897</td>\n",
       "      <td>0.624310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.038283</td>\n",
       "      <td>0.496442</td>\n",
       "      <td>0.418377</td>\n",
       "      <td>0.382421</td>\n",
       "      <td>0.458953</td>\n",
       "      <td>0.551827</td>\n",
       "      <td>0.611314</td>\n",
       "      <td>0.510328</td>\n",
       "      <td>0.487674</td>\n",
       "      <td>0.536979</td>\n",
       "      <td>0.655440</td>\n",
       "      <td>0.575063</td>\n",
       "      <td>0.565827</td>\n",
       "      <td>0.540198</td>\n",
       "      <td>0.618466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.036939</td>\n",
       "      <td>0.492128</td>\n",
       "      <td>0.414415</td>\n",
       "      <td>0.382350</td>\n",
       "      <td>0.472941</td>\n",
       "      <td>0.543397</td>\n",
       "      <td>0.618694</td>\n",
       "      <td>0.514100</td>\n",
       "      <td>0.492290</td>\n",
       "      <td>0.530963</td>\n",
       "      <td>0.655244</td>\n",
       "      <td>0.567758</td>\n",
       "      <td>0.564645</td>\n",
       "      <td>0.546545</td>\n",
       "      <td>0.615834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65526</td>\n",
       "      <td>0.799064</td>\n",
       "      <td>0.618833</td>\n",
       "      <td>0.401570</td>\n",
       "      <td>0.330094</td>\n",
       "      <td>0.492039</td>\n",
       "      <td>0.549652</td>\n",
       "      <td>0.757984</td>\n",
       "      <td>0.477895</td>\n",
       "      <td>0.447763</td>\n",
       "      <td>0.552836</td>\n",
       "      <td>0.582072</td>\n",
       "      <td>0.520940</td>\n",
       "      <td>0.621364</td>\n",
       "      <td>0.531132</td>\n",
       "      <td>0.608913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65527</td>\n",
       "      <td>0.815960</td>\n",
       "      <td>0.588998</td>\n",
       "      <td>0.396941</td>\n",
       "      <td>0.326779</td>\n",
       "      <td>0.492541</td>\n",
       "      <td>0.543088</td>\n",
       "      <td>0.741053</td>\n",
       "      <td>0.456154</td>\n",
       "      <td>0.464268</td>\n",
       "      <td>0.570340</td>\n",
       "      <td>0.551894</td>\n",
       "      <td>0.526051</td>\n",
       "      <td>0.630742</td>\n",
       "      <td>0.524730</td>\n",
       "      <td>0.607009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65528</td>\n",
       "      <td>0.799829</td>\n",
       "      <td>0.542437</td>\n",
       "      <td>0.400740</td>\n",
       "      <td>0.329594</td>\n",
       "      <td>0.468639</td>\n",
       "      <td>0.537588</td>\n",
       "      <td>0.724791</td>\n",
       "      <td>0.450724</td>\n",
       "      <td>0.483579</td>\n",
       "      <td>0.585115</td>\n",
       "      <td>0.522666</td>\n",
       "      <td>0.535451</td>\n",
       "      <td>0.627273</td>\n",
       "      <td>0.521446</td>\n",
       "      <td>0.604874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65529</td>\n",
       "      <td>0.821630</td>\n",
       "      <td>0.497181</td>\n",
       "      <td>0.414988</td>\n",
       "      <td>0.335632</td>\n",
       "      <td>0.439908</td>\n",
       "      <td>0.534898</td>\n",
       "      <td>0.725759</td>\n",
       "      <td>0.454540</td>\n",
       "      <td>0.498602</td>\n",
       "      <td>0.599660</td>\n",
       "      <td>0.516329</td>\n",
       "      <td>0.551335</td>\n",
       "      <td>0.611133</td>\n",
       "      <td>0.524864</td>\n",
       "      <td>0.604196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65530</td>\n",
       "      <td>0.793991</td>\n",
       "      <td>0.466210</td>\n",
       "      <td>0.434759</td>\n",
       "      <td>0.343046</td>\n",
       "      <td>0.434920</td>\n",
       "      <td>0.534188</td>\n",
       "      <td>0.740336</td>\n",
       "      <td>0.465821</td>\n",
       "      <td>0.509668</td>\n",
       "      <td>0.616069</td>\n",
       "      <td>0.525134</td>\n",
       "      <td>0.580632</td>\n",
       "      <td>0.589862</td>\n",
       "      <td>0.529619</td>\n",
       "      <td>0.605444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65531 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             1         2         3         4         5         6         7   \\\n",
       "0      0.039326  0.394546  0.409402  0.351845  0.420885  0.563941  0.614782   \n",
       "1      0.036779  0.438724  0.418747  0.363013  0.415712  0.566265  0.611670   \n",
       "2      0.040571  0.479242  0.422629  0.373950  0.435482  0.561222  0.608771   \n",
       "3      0.038283  0.496442  0.418377  0.382421  0.458953  0.551827  0.611314   \n",
       "4      0.036939  0.492128  0.414415  0.382350  0.472941  0.543397  0.618694   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "65526  0.799064  0.618833  0.401570  0.330094  0.492039  0.549652  0.757984   \n",
       "65527  0.815960  0.588998  0.396941  0.326779  0.492541  0.543088  0.741053   \n",
       "65528  0.799829  0.542437  0.400740  0.329594  0.468639  0.537588  0.724791   \n",
       "65529  0.821630  0.497181  0.414988  0.335632  0.439908  0.534898  0.725759   \n",
       "65530  0.793991  0.466210  0.434759  0.343046  0.434920  0.534188  0.740336   \n",
       "\n",
       "             8         9         10        11        12        13        14  \\\n",
       "0      0.535529  0.488066  0.488956  0.622206  0.564322  0.558791  0.486849   \n",
       "1      0.521770  0.484384  0.507496  0.639967  0.562287  0.561557  0.508049   \n",
       "2      0.512395  0.484983  0.524696  0.650727  0.569639  0.563530  0.527897   \n",
       "3      0.510328  0.487674  0.536979  0.655440  0.575063  0.565827  0.540198   \n",
       "4      0.514100  0.492290  0.530963  0.655244  0.567758  0.564645  0.546545   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "65526  0.477895  0.447763  0.552836  0.582072  0.520940  0.621364  0.531132   \n",
       "65527  0.456154  0.464268  0.570340  0.551894  0.526051  0.630742  0.524730   \n",
       "65528  0.450724  0.483579  0.585115  0.522666  0.535451  0.627273  0.521446   \n",
       "65529  0.454540  0.498602  0.599660  0.516329  0.551335  0.611133  0.524864   \n",
       "65530  0.465821  0.509668  0.616069  0.525134  0.580632  0.589862  0.529619   \n",
       "\n",
       "             15  \n",
       "0      0.634305  \n",
       "1      0.631369  \n",
       "2      0.624310  \n",
       "3      0.618466  \n",
       "4      0.615834  \n",
       "...         ...  \n",
       "65526  0.608913  \n",
       "65527  0.607009  \n",
       "65528  0.604874  \n",
       "65529  0.604196  \n",
       "65530  0.605444  \n",
       "\n",
       "[65531 rows x 15 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the Cleaned Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Load the cleaned data\n",
    "# dataset = pd.read_csv(\"cleaned_augmented_data.csv\", index_col=0)\n",
    "\n",
    "# ## Initialize the class function\n",
    "# feature_extract = helper_function.feature_extraction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Time domain feature extraction\n",
    "# time_features = feature_extract.time_domain(dataset)\n",
    "\n",
    "# ## FFT feature extraction\n",
    "# fft_data = feature_extract.fast_fourier_transform(dataset)\n",
    "# fft_features = feature_extract.energy_dist(fft_data)\n",
    "\n",
    "# ## DCT feature extraction\n",
    "# dct_data = feature_extract.discrete_cosine_transform(dataset)\n",
    "# dct_features = feature_extract.energy_dist(dct_data)\n",
    "\n",
    "# ## MWT feature extraction\n",
    "# mwt_features = feature_extract.morlet_wavelet_transform(dataset)\n",
    "\n",
    "# ## Save the cleaned and augmented feature data\n",
    "# features_pack = {file:data for file,data in \n",
    "#                  zip(['time_feature.csv','fft_feature.csv','dct_feature.csv','mwt_feature.csv'],\n",
    "#                      [time_features, fft_features, dct_features, mwt_features])}\n",
    "\n",
    "# for file_name in features_pack:\n",
    "#     file = feature_extract.feature_data_save(features_pack[file_name])\n",
    "#     export_csv = file.to_csv (file_name, index = True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>class</th>\n",
       "      <th>combo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1011</td>\n",
       "      <td>0.252313</td>\n",
       "      <td>0.164219</td>\n",
       "      <td>0.105858</td>\n",
       "      <td>0.140579</td>\n",
       "      <td>0.062784</td>\n",
       "      <td>0.061097</td>\n",
       "      <td>0.056354</td>\n",
       "      <td>0.039839</td>\n",
       "      <td>0.030838</td>\n",
       "      <td>0.027526</td>\n",
       "      <td>0.022508</td>\n",
       "      <td>0.017129</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1012</td>\n",
       "      <td>0.241576</td>\n",
       "      <td>0.153070</td>\n",
       "      <td>0.086855</td>\n",
       "      <td>0.166372</td>\n",
       "      <td>0.069855</td>\n",
       "      <td>0.060591</td>\n",
       "      <td>0.056431</td>\n",
       "      <td>0.043740</td>\n",
       "      <td>0.034287</td>\n",
       "      <td>0.026592</td>\n",
       "      <td>0.024738</td>\n",
       "      <td>0.017148</td>\n",
       "      <td>0.011228</td>\n",
       "      <td>0.007231</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1013</td>\n",
       "      <td>0.251410</td>\n",
       "      <td>0.133176</td>\n",
       "      <td>0.096997</td>\n",
       "      <td>0.155969</td>\n",
       "      <td>0.069424</td>\n",
       "      <td>0.064857</td>\n",
       "      <td>0.055989</td>\n",
       "      <td>0.040178</td>\n",
       "      <td>0.033815</td>\n",
       "      <td>0.031214</td>\n",
       "      <td>0.028701</td>\n",
       "      <td>0.018272</td>\n",
       "      <td>0.011562</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1014</td>\n",
       "      <td>0.217608</td>\n",
       "      <td>0.175489</td>\n",
       "      <td>0.096809</td>\n",
       "      <td>0.157372</td>\n",
       "      <td>0.065652</td>\n",
       "      <td>0.061248</td>\n",
       "      <td>0.063106</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.035409</td>\n",
       "      <td>0.025043</td>\n",
       "      <td>0.023002</td>\n",
       "      <td>0.016546</td>\n",
       "      <td>0.012686</td>\n",
       "      <td>0.007528</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1015</td>\n",
       "      <td>0.234249</td>\n",
       "      <td>0.153439</td>\n",
       "      <td>0.097816</td>\n",
       "      <td>0.152450</td>\n",
       "      <td>0.072905</td>\n",
       "      <td>0.057822</td>\n",
       "      <td>0.059386</td>\n",
       "      <td>0.044347</td>\n",
       "      <td>0.035477</td>\n",
       "      <td>0.028726</td>\n",
       "      <td>0.025857</td>\n",
       "      <td>0.015888</td>\n",
       "      <td>0.013075</td>\n",
       "      <td>0.008272</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4154</td>\n",
       "      <td>0.044213</td>\n",
       "      <td>0.121859</td>\n",
       "      <td>0.296893</td>\n",
       "      <td>0.126379</td>\n",
       "      <td>0.084246</td>\n",
       "      <td>0.123101</td>\n",
       "      <td>0.078802</td>\n",
       "      <td>0.035788</td>\n",
       "      <td>0.024655</td>\n",
       "      <td>0.017818</td>\n",
       "      <td>0.019731</td>\n",
       "      <td>0.018507</td>\n",
       "      <td>0.004435</td>\n",
       "      <td>0.003375</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4155</td>\n",
       "      <td>0.048727</td>\n",
       "      <td>0.114272</td>\n",
       "      <td>0.316183</td>\n",
       "      <td>0.115304</td>\n",
       "      <td>0.076656</td>\n",
       "      <td>0.111922</td>\n",
       "      <td>0.084681</td>\n",
       "      <td>0.034327</td>\n",
       "      <td>0.025405</td>\n",
       "      <td>0.017908</td>\n",
       "      <td>0.026565</td>\n",
       "      <td>0.022270</td>\n",
       "      <td>0.003275</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4156</td>\n",
       "      <td>0.040700</td>\n",
       "      <td>0.115426</td>\n",
       "      <td>0.304084</td>\n",
       "      <td>0.138541</td>\n",
       "      <td>0.072132</td>\n",
       "      <td>0.130518</td>\n",
       "      <td>0.076536</td>\n",
       "      <td>0.031729</td>\n",
       "      <td>0.023394</td>\n",
       "      <td>0.020744</td>\n",
       "      <td>0.020226</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>0.003036</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4157</td>\n",
       "      <td>0.042053</td>\n",
       "      <td>0.124506</td>\n",
       "      <td>0.335482</td>\n",
       "      <td>0.126887</td>\n",
       "      <td>0.080827</td>\n",
       "      <td>0.106150</td>\n",
       "      <td>0.066960</td>\n",
       "      <td>0.033360</td>\n",
       "      <td>0.021897</td>\n",
       "      <td>0.017661</td>\n",
       "      <td>0.018707</td>\n",
       "      <td>0.018878</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4158</td>\n",
       "      <td>0.026455</td>\n",
       "      <td>0.106082</td>\n",
       "      <td>0.274667</td>\n",
       "      <td>0.139687</td>\n",
       "      <td>0.081461</td>\n",
       "      <td>0.128744</td>\n",
       "      <td>0.081393</td>\n",
       "      <td>0.043923</td>\n",
       "      <td>0.032257</td>\n",
       "      <td>0.022226</td>\n",
       "      <td>0.029783</td>\n",
       "      <td>0.024283</td>\n",
       "      <td>0.005377</td>\n",
       "      <td>0.003576</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "1011  0.252313  0.164219  0.105858  0.140579  0.062784  0.061097  0.056354   \n",
       "1012  0.241576  0.153070  0.086855  0.166372  0.069855  0.060591  0.056431   \n",
       "1013  0.251410  0.133176  0.096997  0.155969  0.069424  0.064857  0.055989   \n",
       "1014  0.217608  0.175489  0.096809  0.157372  0.065652  0.061248  0.063106   \n",
       "1015  0.234249  0.153439  0.097816  0.152450  0.072905  0.057822  0.059386   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4154  0.044213  0.121859  0.296893  0.126379  0.084246  0.123101  0.078802   \n",
       "4155  0.048727  0.114272  0.316183  0.115304  0.076656  0.111922  0.084681   \n",
       "4156  0.040700  0.115426  0.304084  0.138541  0.072132  0.130518  0.076536   \n",
       "4157  0.042053  0.124506  0.335482  0.126887  0.080827  0.106150  0.066960   \n",
       "4158  0.026455  0.106082  0.274667  0.139687  0.081461  0.128744  0.081393   \n",
       "\n",
       "             7         8         9        10        11        12        13  \\\n",
       "1011  0.039839  0.030838  0.027526  0.022508  0.017129  0.011811  0.006983   \n",
       "1012  0.043740  0.034287  0.026592  0.024738  0.017148  0.011228  0.007231   \n",
       "1013  0.040178  0.033815  0.031214  0.028701  0.018272  0.011562  0.008214   \n",
       "1014  0.042254  0.035409  0.025043  0.023002  0.016546  0.012686  0.007528   \n",
       "1015  0.044347  0.035477  0.028726  0.025857  0.015888  0.013075  0.008272   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4154  0.035788  0.024655  0.017818  0.019731  0.018507  0.004435  0.003375   \n",
       "4155  0.034327  0.025405  0.017908  0.026565  0.022270  0.003275  0.002314   \n",
       "4156  0.031729  0.023394  0.020744  0.020226  0.018600  0.004134  0.003036   \n",
       "4157  0.033360  0.021897  0.017661  0.018707  0.018878  0.003868  0.002669   \n",
       "4158  0.043923  0.032257  0.022226  0.029783  0.024283  0.005377  0.003576   \n",
       "\n",
       "      class  combo  \n",
       "1011      1      1  \n",
       "1012      1      1  \n",
       "1013      1      1  \n",
       "1014      1      1  \n",
       "1015      1      1  \n",
       "...     ...    ...  \n",
       "4154      4     15  \n",
       "4155      4     15  \n",
       "4156      4     15  \n",
       "4157      4     15  \n",
       "4158      4     15  \n",
       "\n",
       "[480 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load feature data\n",
    "files = ['time_feature','fft_feature','dct_feature','mwt_feature']\n",
    "dataset = [None]*len(files)\n",
    "path = os.getcwd()+'/features_files/peneration/'\n",
    "\n",
    "for i in range(len(files)):\n",
    "    data = pd.read_csv(path+files[i]+'.csv', index_col=0)\n",
    "    dataset[i] = data\n",
    "dataset = {name:data for name,data in zip(files,dataset)}\n",
    "dataset['fft_feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/aslanfeng/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_model = helper_function.classification()\n",
    "\n",
    "data = dataset['fft_feature']\n",
    "data = data.values\n",
    "X, Y = nn_model.create_dataset(data)\n",
    "\n",
    "nn_results = nn_model.mlp_model(X,Y)\n",
    "svm_acc, svm_cm = nn_model.svm_ml(X,Y)\n",
    "\n",
    "\n",
    "# files = ['time_feature','fft_feature','dct_feature','mwt_feature']\n",
    "# comb_num = 15\n",
    "\n",
    "# df = pd.DataFrame()\n",
    "# # Feature loop\n",
    "# for feature in files:\n",
    "#     feature_data = dataset[feature]\n",
    "#     combo_results = [None]*(comb_num+1)\n",
    "#     # Combination loop\n",
    "#     for i in range(1,comb_num+1): \n",
    "#         data = feature_data[feature_data['combo']==i]\n",
    "#         data = data.values\n",
    "#         X, Y = nn_model.create_dataset(data)\n",
    "#         model_results = [nn_model.mlp_model(X,Y) for _ in range(3)]\n",
    "#         combo_results[i] = np.mean(model_results)   \n",
    "#     results = pd.DataFrame(combo_results)\n",
    "#     results.columns = [feature]\n",
    "#     df = pd.concat([df, results], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[96.66666388511658, 99.16666746139526, 98.33333492279053]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.16666666666667"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils.multiclass import unique_labels\n",
    "# def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "#                           normalize=False,\n",
    "#                           title=None,\n",
    "#                           cmap=plt.cm.Blues):\n",
    "#     \"\"\"\n",
    "#     This function prints and plots the confusion matrix.\n",
    "#     Normalization can be applied by setting `normalize=True`.\n",
    "#     \"\"\"\n",
    "#     if not title:\n",
    "#         if normalize:\n",
    "#             title = 'Normalized confusion matrix'\n",
    "#         else:\n",
    "#             title = 'Confusion matrix, without normalization'\n",
    "\n",
    "#     # Compute confusion matrix\n",
    "#     cm = confusion_matrix(y_true, y_pred)\n",
    "#     # Only use the labels that appear in the data\n",
    "# #     classes = classes[unique_labels(y_true, y_pred)]\n",
    "#     classes = [1,2,3,4]\n",
    "#     if normalize:\n",
    "#         cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "#     else:\n",
    "#         print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(8,8))\n",
    "#     im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     ax.figure.colorbar(im, ax=ax)\n",
    "#     # We want to show all ticks...\n",
    "#     ax.set(xticks=np.arange(cm.shape[1]),\n",
    "#            yticks=np.arange(cm.shape[0]),\n",
    "#            # ... and label them with the respective list entries\n",
    "#            xticklabels=classes, yticklabels=classes,\n",
    "#            title=title,\n",
    "#            ylabel='True label',\n",
    "#            xlabel='Predicted label')\n",
    "\n",
    "#     # Rotate the tick labels and set their alignment.\n",
    "#     plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "#              rotation_mode=\"anchor\")\n",
    "\n",
    "#     # Loop over data dimensions and create text annotations.\n",
    "#     fmt = '.2f' if normalize else 'd'\n",
    "#     thresh = cm.max() / 2.\n",
    "#     for i in range(cm.shape[0]):\n",
    "#         for j in range(cm.shape[1]):\n",
    "#             ax.text(j, i, format(cm[i, j], fmt),\n",
    "#                     ha=\"center\", va=\"center\",\n",
    "#                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "#     fig.tight_layout()\n",
    "#     return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries \n",
    "from sklearn import datasets \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "  \n",
    "# dividing X, y into train and test data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y) \n",
    "  \n",
    "# training a linear SVM classifier \n",
    "from sklearn.svm import SVC \n",
    "svm_model_linear = SVC(kernel = 'poly', gamma='scale').fit(X_train, y_train) \n",
    "svm_predictions = svm_model_linear.predict(X_test) \n",
    "  \n",
    "# model accuracy for X_test   \n",
    "acc = accuracy_score(y_test, svm_predictions)*100\n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test, svm_predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.33%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {}%\".format(round(acc,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[1.         0.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.06451613 0.         0.93548387 0.        ]\n",
      " [0.         0.         0.         1.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test, svm_predictions, classes=[1,2,3,4], normalize=True, \n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
